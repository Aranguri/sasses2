{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ask Me Anything. Dynamic Memory Networks for Natural Language Processing\n",
    "## Overview\n",
    "Summary: transform the input and the question. Repeat n times: generate memory m_t by combining the facts that are relevant (relevance is measured as the similarity between fact and m_{t-1} and fact and question.) Untransform the answer from the last memory, m_T.\n",
    "Steps:\n",
    "* Input: in: input sentence. out: contextual representation of the input\n",
    "* Question: in: question sentence. out: contextual representation of the question.\n",
    "* Memory: repeat n times: in: question, facts, m_t. out: m_{t+1}\n",
    "* Answer: in: last memory. out: output sentence (answer)\n",
    "\n",
    "## Input\n",
    "We use word embeddings for the input sentence.\n",
    "If we have only one sentence, we can think about the GRU in two ways\n",
    "* adding context to the words. Eg, the word embeddings for \"it\" would be the same for \"It is good to have pickles\" as for \"This dog is happy because it is running.\". However, after using the GRU (and thus adding the context) the first \"it\" (ideally) would represent an abstract word whereas the second \"it\" would represent the dog. \n",
    "* making smooth the representation of a sentence. Often, the words forming a sentence are related, but they can be very different. Thus, after using the GRU, each word is nearer the semantic mean of the words in the sentence.[1]\n",
    "If we have multiple sentences, we only take the hidden states of the GRU that were produced after reading an End of Sentence (EOS) token. We can think about this GRU as compressing the independent meaning of each word into one vector. It's not only that, but also we use the previous compressed sentences to make a better compression of the following sentences. {Try BiGRU. Try cleaning the hidden state after receiving a dot as input.}\n",
    "\n",
    "Notice that the GRU is flexible and its behavior changes depending on what we take from it to use in the next step. This happens because what we take from it is the place where we send the backpropagation flow.\n",
    "\n",
    "$X = word\\_embeddings([w_1, w_2, ... , w_n])$\n",
    "\n",
    "$h_t = GRU(x_t, h_{t-1})$\n",
    "    \n",
    "$if\\, sentences(input) == 1: C = H$\n",
    "\n",
    "$else: C = \\{h_i | h_i \\verb| was hidden state after EOS|\\}$\n",
    "\n",
    "## Question\n",
    "Similar to the input. Here we always use all hidden states. (We use the same word embeddings for input and question)\n",
    "\n",
    "$Q = word\\_embeddings([qw_1, qw_2, ..., qw_n])$ \n",
    "\n",
    "$h_t = GRU(q_t, h_{t-1})$\n",
    "\n",
    "return $h_T$\n",
    "\n",
    "## Memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similarity measure\n",
    "First, we want to measure the similarity between the contextualized word we are retrieveing and the question/memory state. To do this, we define a feature vector z with several types of interactions. (Notice we only care about the interactions that include c; the interactions between m and q are the same for every fact c.)\n",
    "\n",
    "$z(c, m, q) = [c, m, q, c ◦ q, c ◦ m, |c − q|, |c − m|, c^TWq, c^TWm]$ [2]\n",
    "\n",
    "We want to measure the similarity to know the importance of a contextualized word for the given context. Thus, we want one scalar as a result. It also makes sense to measure interactions between the interactions. These two reasons lead to use a nn on the result of the feature vector.\n",
    "\n",
    "$G(c, m, q) = nn(z(c, m, q))$\n",
    "\n",
    "$nn(x) = sigmoid(wb(tanh(wb(x))))$\n",
    "\n",
    "{try the generalized_hadamard(x, y) = hadamard(x, affine(y)) = x ◦ Ay}\n",
    "\n",
    "{try removing values from the feature vector. does the performance change?}\n",
    "\n",
    "### Memory module\n",
    "Now, the first GRU eats one by one the contextualized words (produced by the input module.) In this way, we compute a single representation of the data, which is the last hidden state. Then, this hidden states is used to update the memory. The gate in the first equation allows us to skip contextualized words that weren't similar to the question nor the memory state. (This gate is parameterized by $g_t^i = G(c_t, m_{t-1}, q)$)\n",
    "\n",
    "$h^i_t = gate(GRU(c_t, h^i_{t-1}), h^i_{t-1})$\n",
    "\n",
    "$e^i = h^i_{T_c}$\n",
    "\n",
    "$m^i = GRU(e^i, m^{i - 1})$\n",
    "\n",
    "What's $e^i$ for? At each timestep, we want to update the memory based on the facts that are useful. To detect whether a fact is useful, we compute the similarity between the fact and the previous memory and between the fact and the question.\n",
    "\n",
    "Notice that the way we compute $e^i$ puts an emphasis on the last part of the sentence.[3] It seems an useful prior/assumption for tasks that ask about the actual state of the world. So if we changed something from place a hundred times, we only care about the last change. It's not clear to me if this generalizes well to all human tasks.\n",
    "\n",
    "## Answer module\n",
    "The last memory (ideally) contains the answer to the question. But the answer to the question could be a bunch of words. So we take a GRU that can decouple information from the hidden state and produce the words to answer the question. \n",
    "\n",
    "$a_0 = m^{T_M}$\n",
    "\n",
    "$a_t = GRU([q, y_{t-1}], a_{t-1})$\n",
    "\n",
    "$y_t = softargmax(Wa_t)$\n",
    "\n",
    "Notice we input the question to the GRU at every timestep, but we input the memory only one time (as the initial state.) This structure gives more importance to always having clear the whole question. Also, this structure allows us to remove step by step what we already answered from the hidden state, while we keep the question untouched.\n",
    "\n",
    "## Related work\n",
    "The sequence-to-sequence model is a special case of the DMN. In the sequence-to-sequence model we encode the input sentence into one hidden state, and then we use decode the output from that hidden state. In the DMN, we use a rnn to encode the facts $c_t$ into $e^i.$ Then, we use $m^i$ that in the special case of the sequence to sequence model is equal to $e^i$ and peel off the output words that will form the sentence.\n",
    "\n",
    "## Results\n",
    "The model is good at processing information when multiple reasoning steps are required. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes\n",
    "[1] Let's call X to the input and f(X) to the output of a BiRNN. The smoothing view suggests applying f several times. That is, the first time we apply the RNN each word goes from $x_i$ to $f(x_i),$ the second time each word goes from $f(x_i)$ to $f(f(x_i))$ and so on. Say we apply this function n times, and we take the limit of n tending to infinity. In this way, we are maybe computing the \"semantic\" mean of the words that form the sentence. The value of n determines how smooth the representation of the sentence is. Under this view, doing only one pass in the RNN seems rather arbitrary. It's somewhat annoying that we need to deal with different words in different places, because the different places also cause different meanings. If we need to compute the \"semantic\" mean of independent words (ie words that aren't in a sentence,) then using a weighted average seems good enough. But that isn't the case for sentences. \n",
    "\n",
    "[2] It's interesting to consider how we would measure the interaction of three things using only one metric as opposed to using several metrics (eg a - b, b - c, and c - a.) Say we have 3 vectors and we want to see how similar they are. Let's see some cases\n",
    "* s(a, a, a) = 1\n",
    "* s(a, a, b) = s(a, b, b)\n",
    "* a, b, and c are the three basis vectors in 3D => s(a, b, c) = 0\n",
    "One quantity could be 1 / det([a, b, c]). This is considering that a, b, and c are unit vectors and they are independent. \n",
    "Another quantity could be the hadamard product between the three divided by the magnitudes. Another could be having a 3D tensor. First, notice that we can compute the simliarity between two vectors as $x^TAy$ with A a matrix (or 2D tensor.) It's analogous to computing (Ay)x. It's also analogous to computing $\\sum_{i, j} a_{i, j}x_iy_j.$ This last definition is interesting: we are computing a weighted sum of the interaction between pairs of elements. \n",
    "\n",
    "For the last sentence, we use the fact that multiplying two elements is the same as calculating their interaction. There's a caveat here: we need to normalize the elements. Otherwise, the vector [2, 1] would be more similar to [1, 1] than [1, 1] itself. The idea of normalizing is that if we constrain that a and b should add to a constant c, then a * b can be used as a measure of similarity. Let's see some examples (with c = 2.)\n",
    "* a = 1, b = 1 => s(a, b) = a * b = 1\n",
    "* a = .5, b = 1.5 => s(a, b) = a * b = .75\n",
    "* a = 1.5, b = .5 => s(a, b) = .75\n",
    "* a = 0, b = 2 => s(a, b) = 0\n",
    "\n",
    "Now, say we want to compare 3 vectors. From the last definition we used, the extension is natural $\\sum_{i, j, k} a_{i, j, k}x_iy_jz_k.$ This is the same as having a 3D tensor A and calculating ((Ax)y)z. It's interesting to consider the first operation Az. Here we have a 3D tensor and a vector Z and we reduce both things to a single matrix. What does this matrix represent?\n",
    "\n",
    "What if we want to compute more complex interactions?\n",
    "\n",
    "Does it appear in nature the necessity of measuring the interaction between three, or n, things? let's think of when we need to measure the interaction between two things. For kNNs, we want to know the vectors that are nearest to the query vector. So to know whether a data-vector is near to the query-vector, we compute the dot product between the vectors. \n",
    "\n",
    "Say we have some sets of vectors. Each set of vectors corresponds to a different category. We could think about each set of vectors as being a set of images of an animal. So, vectors in the same set have different images of the same animals. And vectors in different sets have images about different animals. Now, we have a new image and we want to predict its category. One way to do this is by computing the independent distances between data-vector and query-vector. {we could take into account the variance in a given group, so if the vectors in a set have a lot of variance, we conform with a vector that doesn't have that is distant.}\n",
    "\n",
    "Using the current formulation, the time and space complexity of the operation is exponential in the number of things we want to compare. In reality, I think that A (the comparison tensor) would be sparse. This is because most of the interactions would be useless \n",
    "\n",
    "[3] Another valid approach to compute $e^i$ would be to do $attention(c, weights=g)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
