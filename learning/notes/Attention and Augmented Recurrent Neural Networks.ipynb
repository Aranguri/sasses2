{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# https://distill.pub/2016/augmented-rnns/\n",
    "## Attention\n",
    "Content-based attetnion: we have a query and we compute the dot-product between each input vector and the query. That gives us the similarity between the query and each vector in the input. (We use a softargmax.) Then, we use that similarity to compute the weighted sum of all the input.\n",
    "\n",
    "## Adaptive computation time\n",
    "We want to give more process to some inputs if required. Thus, to make it differentiable, we take the expectation of several models (a model with one step, two steps, three steps, and so on.) We have a budget of 1. Every step takes some portion of the budget and multiplies its output by that portion. That represents the contribution of that step to the output. So, when it only remains less than epsilon from the budget, we stop adding more steps."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
